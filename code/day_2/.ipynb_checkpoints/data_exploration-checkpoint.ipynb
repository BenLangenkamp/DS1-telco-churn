{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a480af",
   "metadata": {},
   "source": [
    "### First steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import termplotlib as tpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860656e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location of the data\n",
    "meta_path = '../../data/day_2/boston_housing/meta.txt'\n",
    "data_path = '../../data/day_2/boston_housing/housing_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced10340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the file size\n",
    "print(\"Size of metadata:\", os.path.getsize(meta_path), \"Bytes\")\n",
    "print(\"Size of data:\", os.path.getsize(data_path), \"Bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0520cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "\n",
    "# Loading the metadata\n",
    "with open(meta_path, 'r', encoding='utf-8') as f:\n",
    "    meta = f.read()\n",
    "\n",
    "# Loading the dataset as DataFrame\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce6d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the metadata\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ffc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de162298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatypes of the columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc66ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dimensions\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa36824",
   "metadata": {},
   "source": [
    "### Quality Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a5aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring completeness\n",
    "missing_count = df.isna().sum()\n",
    "print(missing_count)\n",
    "missing_rate = df.isna().mean()\n",
    "print(missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e471d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring uniqueness\n",
    "duplicate_rate = df.duplicated()\n",
    "print(duplicate_rate) # Percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6021f",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137047f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring cardinality\n",
    "distinct_vals = df.nunique()\n",
    "print(distinct_vals) # Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns with low cardinality and analyze their values\n",
    "\n",
    "# Define threshold for low cardinality\n",
    "cardinality_threshhold = 0.66\n",
    "cutoff = cardinality_threshhold * len(df)\n",
    "low_cardinality_columns = distinct_vals[distinct_vals < cutoff].index.tolist()\n",
    "print(\"Selected low cardinality coluns: \", low_cardinality_columns)\n",
    "\n",
    "# Print the value counts for each column\n",
    "for col in low_cardinality_columns:\n",
    "    print(\"\")\n",
    "    print(f\"Spalte: {col}\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract high cardinality columns and analyze their values\n",
    "\n",
    "# Derive high cardinality columns\n",
    "high_cardinality_columns = distinct_vals[distinct_vals > cutoff].index.tolist()\n",
    "print(\"Selected high cardinality coluns: \", high_cardinality_columns)\n",
    "\n",
    "# Set a bucket number and show the values counts of buckets\n",
    "num_buckets = 16\n",
    "\n",
    "for col in high_cardinality_columns:\n",
    "    print(\"\")\n",
    "    print(f\"Spalte: {col}\")\n",
    "    buckets = pd.cut(df[col], bins=num_buckets)\n",
    "    bucket_counts = buckets.value_counts().sort_index()\n",
    "    print(bucket_counts)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831033bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the discrete distribution of RM values\n",
    "\n",
    "# Get the RM column values as an array\n",
    "rm_data = df[\"RM\"].values\n",
    "\n",
    "# Calculate the histogram for RM\n",
    "counts, bin_edges = np.histogram(rm_data, bins=64)\n",
    "\n",
    "# Show the histogram\n",
    "fig = tpl.figure()\n",
    "fig.hist(counts, bin_edges, grid=[15, 40], force_ascii=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a contigency table for CHAS and RAD\n",
    "contingency_table = pd.crosstab(df['CHAS'], df['RAD'], normalize=\"index\")\n",
    "print(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e8ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a correlation matrix of all columns except CHAS and RAD\n",
    "corr_matrix = df[df.columns.difference(['CHAS', 'RAD'])].corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d4d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the top five results of the correlation matrix\n",
    "\n",
    "# Unstack correlation matrix to long format\n",
    "corr_long = corr_matrix.unstack().reset_index()\n",
    "corr_long.columns = ['variable_1', 'variable_2', 'correlation']\n",
    "\n",
    "# Remove self correlations (e.g., A vs A)\n",
    "corr_long = corr_long[corr_long['variable_1'] != corr_long['variable_2']]\n",
    "\n",
    "# Remove duplicate pairs (because matrix is symmetric)\n",
    "corr_long['pairs'] = corr_long.apply(lambda row: tuple(sorted([row['variable_1'], row['variable_2']])), axis=1)\n",
    "corr_long = corr_long.drop_duplicates(subset='pairs')\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "corr_long['abs_correlation'] = corr_long['correlation'].abs()\n",
    "top5 = corr_long.sort_values(by='abs_correlation', ascending=False).head(5)\n",
    "\n",
    "# Output (original correlation values)\n",
    "print(top5[['variable_1', 'variable_2', 'correlation']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
